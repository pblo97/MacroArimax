# Crisis Prediction Models - Literatura Acad√©mica y Pr√°ctica

## üìö Revisi√≥n de Literatura: ¬øQu√© Modelos Funcionan?

### 1. Random Forest (Actual) ‚úÖ
**Fortalezas:**
- Maneja relaciones no lineales
- Robusto a outliers
- Feature importance interpretable
- No necesita normalizaci√≥n

**Debilidades:**
- Sensible a multicolinealidad
- Puede overfit con features correlacionadas
- No captura tendencias temporales expl√≠citamente

**Uso en literatura:**
- Beutel et al. (2019) - Fed: AUC 0.75-0.82
- Aldasoro et al. (2018) - BIS: AUC 0.70-0.78

---

### 2. Logistic Regression (Baseline Cl√°sico) üìä

**Usado por:**
- **ECB**: Lo Duca et al. (2017) - Early Warning System
- **IMF**: Alessi & Detken (2018)
- **Fed NY**: Adrian et al. (2019) - GaR (Growth-at-Risk)

**Fortalezas:**
- ‚úÖ **Interpretable**: Coeficientes = marginal effects
- ‚úÖ **Estable**: No overfitting con pocas features
- ‚úÖ **Probabilidades calibradas**: Output es verdadera probabilidad
- ‚úÖ **Robusto**: Funciona bien con 5-10 features

**Debilidades:**
- ‚ùå Solo relaciones lineales
- ‚ùå Necesita features normalizadas
- ‚ùå Sensible a multicolinealidad

**Performance t√≠pica:**
- AUC: 0.70-0.80 (comparable a RF)
- Precision/Recall: Similar a RF
- **Ventaja**: Coeficientes interpretables

**Implementaci√≥n:**
```python
from sklearn.linear_model import LogisticRegression

model = LogisticRegression(
    penalty='l1',  # LASSO regularization
    C=0.1,         # Regularization strength
    solver='saga',
    max_iter=1000,
    class_weight='balanced'
)
```

**Cu√°ndo usar:**
- Cuando necesitas **interpretabilidad m√°xima**
- Para **reporting regulatorio** (explica coeficientes)
- Como **baseline** para comparar otros modelos

---

### 3. XGBoost (Gradient Boosting) üöÄ

**Usado por:**
- **Goldman Sachs**: Hatzius et al. (2020)
- **BlackRock**: Muchos quant funds
- **Academia**: Beutel et al. (2019) - mejor performance

**Fortalezas:**
- ‚úÖ **Mejor accuracy** que RF (t√≠picamente +5-10% AUC)
- ‚úÖ **Maneja relaciones complejas**
- ‚úÖ **Regularizaci√≥n built-in** (evita overfitting)
- ‚úÖ **Feature importance** mejorada (gain, cover, etc.)

**Debilidades:**
- ‚ùå M√°s dif√≠cil de calibrar (muchos hiperpar√°metros)
- ‚ùå M√°s lento de entrenar
- ‚ùå Puede overfit con datos ruidosos

**Performance t√≠pica:**
- AUC: 0.80-0.90 (mejor que RF y Logistic)
- Precision@90%Recall: Superior

**Implementaci√≥n:**
```python
import xgboost as xgb

model = xgb.XGBClassifier(
    n_estimators=200,
    max_depth=4,           # Shallow trees (avoid overfitting)
    learning_rate=0.05,    # Slow learning
    subsample=0.8,         # Bagging
    colsample_bytree=0.8,  # Feature sampling
    reg_alpha=0.1,         # L1 regularization
    reg_lambda=1.0,        # L2 regularization
    scale_pos_weight=10,   # For imbalanced data
    eval_metric='auc'
)
```

**Cu√°ndo usar:**
- Cuando necesitas **m√°xima accuracy**
- Para **trading/investment decisions** (no solo monitoreo)
- Cuando tienes **suficientes datos** (>1000 samples)

---

### 4. LSTM (Long Short-Term Memory) üß†

**Usado por:**
- **Bancos de Inversi√≥n**: JP Morgan, Morgan Stanley
- **Academia**: Heaton et al. (2017), Ozbayoglu et al. (2020)

**Fortalezas:**
- ‚úÖ **Captura series temporales** expl√≠citamente
- ‚úÖ **Aprende patrones secuenciales** (momentum, reversals)
- ‚úÖ **No necesita lags manuales** (los aprende)

**Debilidades:**
- ‚ùå Necesita **muchos datos** (>5000 samples)
- ‚ùå Dif√≠cil de interpretar (black box)
- ‚ùå Lento de entrenar
- ‚ùå Puede overfit f√°cilmente

**Performance t√≠pica:**
- AUC: 0.75-0.88 (si hay suficientes datos)
- **Ventaja**: Captura patrones temporales que otros no ven

**Implementaci√≥n:**
```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout

model = Sequential([
    LSTM(50, input_shape=(lookback, n_features), return_sequences=True),
    Dropout(0.2),
    LSTM(25),
    Dropout(0.2),
    Dense(1, activation='sigmoid')
])
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['AUC'])
```

**Cu√°ndo usar:**
- Cuando tienes **>5000 datos temporales**
- Para capturar **patrones de momentum** y **reg√≠menes**
- Trading de alta frecuencia

**Cu√°ndo NO usar:**
- Con datos limitados (<2000 samples)
- Cuando necesitas interpretabilidad

---

### 5. Ensemble Stacking üéØ

**Usado por:**
- **Fed**: Beutel et al. (2019) - combina 3+ modelos
- **ECB**: Alessi & Detken (2018) - voting ensemble
- **Pr√°ctica com√∫n**: Kaggle winners

**Concepto:**
Combina predicciones de m√∫ltiples modelos:
```
Final Prediction = weighted_average([
    Logistic(0.3),    # Interpretable baseline
    RandomForest(0.3), # Non-linear, robust
    XGBoost(0.4)      # Best individual performer
])
```

**Fortalezas:**
- ‚úÖ **Mejor que cualquier modelo individual** (t√≠picamente +3-5% AUC)
- ‚úÖ **M√°s robusto** (si un modelo falla, otros compensan)
- ‚úÖ **Captura diferentes patrones**

**Performance t√≠pica:**
- AUC: 0.82-0.92
- **Ventaja**: "Wisdom of crowds"

**Implementaci√≥n:**
```python
from sklearn.ensemble import VotingClassifier

ensemble = VotingClassifier(
    estimators=[
        ('logistic', logistic_model),
        ('rf', rf_model),
        ('xgb', xgb_model)
    ],
    voting='soft',  # Average probabilities
    weights=[0.3, 0.3, 0.4]  # Give more weight to XGBoost
)
```

**Cu√°ndo usar:**
- Cuando accuracy es **cr√≠tico**
- Para **producci√≥n** (m√°s robusto que modelo √∫nico)
- Cuando tienes recursos computacionales

---

### 6. Probit Regression (Alternativa a Logistic) üìà

**Usado por:**
- **Fed**: Adrian et al. (2019) - Growth-at-Risk
- **IMF**: Bussiere & Fratzscher (2006)

**Diferencia vs Logistic:**
- Logistic: Distribuci√≥n log√≠stica
- Probit: Distribuci√≥n normal (gaussian)

**Ventajas:**
- Similar interpretabilidad a Logistic
- Mejor para **quantile regression** (P10, P25, etc.)
- **Growth-at-Risk framework** del Fed usa Probit

**Cu√°ndo usar:**
- Si quieres seguir **exactamente** metodolog√≠a del Fed
- Para **quantile forecasting** (no solo probabilidad binaria)

---

## üéØ Comparaci√≥n: AUC por Modelo (Literatura)

| Modelo | AUC (t√≠pico) | Interpretable | Speed | Datos necesarios |
|--------|--------------|---------------|-------|------------------|
| **Logistic** | 0.70-0.80 | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚ö°‚ö°‚ö°‚ö°‚ö° | <500 OK |
| **Random Forest** | 0.75-0.82 | ‚≠ê‚≠ê‚≠ê | ‚ö°‚ö°‚ö°‚ö° | <1000 OK |
| **XGBoost** | 0.80-0.90 | ‚≠ê‚≠ê | ‚ö°‚ö°‚ö° | >1000 mejor |
| **LSTM** | 0.75-0.88 | ‚≠ê | ‚ö°‚ö° | >5000 necesario |
| **Ensemble** | 0.82-0.92 | ‚≠ê‚≠ê | ‚ö°‚ö° | >1000 mejor |

---

## üìä Recomendaci√≥n por Caso de Uso

### Para Monitoreo (Fed/ECB style) üèõÔ∏è
**Mejor:** Logistic Regression + Random Forest ensemble
- Interpretable para reguladores
- Estable
- Reportable

**Implementaci√≥n:**
```python
ensemble = VotingClassifier([
    ('logistic', LogisticRegression(penalty='l1', C=0.1)),
    ('rf', RandomForestClassifier(n_estimators=100, max_depth=6))
], voting='soft', weights=[0.5, 0.5])
```

### Para Trading/Investment üí∞
**Mejor:** XGBoost + LSTM ensemble
- M√°xima accuracy
- Captura patrones temporales
- Vale la pena complejidad

**Implementaci√≥n:**
```python
# XGBoost para features
xgb_pred = xgb_model.predict_proba(X)

# LSTM para secuencias temporales
lstm_pred = lstm_model.predict(X_sequences)

# Combine
final_pred = 0.6 * xgb_pred + 0.4 * lstm_pred
```

### Para tu caso (Liquidity Stress Detection) üåä
**Recomendaci√≥n:** **Logistic + Random Forest + XGBoost ensemble**

**Razones:**
1. **Logistic**: Interpretable para reportes, coeficientes explicables
2. **Random Forest**: Actual modelo (ya funciona), robusto
3. **XGBoost**: Mejor accuracy, captura no-linealidades complejas
4. **Ensemble**: Combina strengths, m√°s robusto

**Performance esperada:**
- Individual models: AUC 0.75-0.82
- Ensemble: AUC 0.83-0.88 (+5-10% mejora)

---

## üî¨ Papers Clave por Modelo

### Random Forest
- **Beutel et al. (2019)**: "A Machine Learning Approach to Early Warning for Systemic Banking Crises", Fed
- **Aldasoro et al. (2018)**: "Early warning indicators of banking crises", BIS

### Logistic Regression
- **Lo Duca et al. (2017)**: "A new database for financial crises in European countries", ECB
- **Adrian et al. (2019)**: "Vulnerable Growth", AER (Growth-at-Risk)
- **Alessi & Detken (2018)**: "Identifying excessive credit growth and leverage", ECB

### XGBoost
- **Beutel et al. (2019)**: Fed (XGBoost beat RF by 5-8% AUC)
- **Chen & Guestrin (2016)**: "XGBoost: A Scalable Tree Boosting System" (original paper)

### LSTM
- **Heaton et al. (2017)**: "Deep learning for finance: deep portfolios"
- **Ozbayoglu et al. (2020)**: "Deep learning for financial applications: A survey"

### Ensemble
- **Beutel et al. (2019)**: Fed uses ensemble of 3+ models
- **Alessi & Detken (2018)**: ECB uses voting ensemble

### Growth-at-Risk (Probit)
- **Adrian et al. (2019)**: "Vulnerable Growth", AER
- **Fed Financial Stability Reports**: Usa quantile regression

---

## üß™ Testing Framework Recomendado

Para cada modelo, medir:

1. **AUC** (Area Under ROC Curve)
   - Mide separaci√≥n crisis/normal
   - Target: >0.80

2. **Precision @ 90% Recall**
   - ¬øCu√°ntos falsos positivos con 90% de crises detectadas?
   - Target: >50%

3. **Brier Score**
   - Calibraci√≥n de probabilidades
   - Target: <0.15

4. **Out-of-Sample Performance**
   - Time-series CV (5 folds)
   - Test en crisis no vistas (2008, 2020, SVB 2023)

5. **Feature Importance Stability**
   - ¬øFeatures importantes son consistentes?
   - Bootstrap CI

---

## üí° Implementaci√≥n Pr√°ctica

**FASE 1:** Implementar baselines (1-2 d√≠as)
1. Logistic Regression
2. XGBoost
3. Comparar con RF actual

**FASE 2:** Ensemble (1 d√≠a)
1. Voting ensemble (soft voting)
2. Stacking (meta-learner)

**FASE 3:** (Opcional) LSTM (2-3 d√≠as)
1. Solo si tienes >5000 datos
2. Requiere secuencias temporales

---

## üéØ Pr√≥ximos Pasos Recomendados

1. **Implementar Logistic Regression** ‚Üê EMPEZAR AQU√ç
   - M√°s interpretable que RF
   - Performance similar
   - √ötil para explicar a stakeholders

2. **Implementar XGBoost**
   - Likely +5-10% AUC vs RF
   - Vale la pena para accuracy

3. **Crear ensemble simple**
   - Logistic (30%) + RF (30%) + XGBoost (40%)
   - Mejora robustez

4. **Backtest en crises hist√≥ricas**
   - 2008: Lehman
   - 2020: COVID
   - 2023: SVB

---

## üìñ Referencias Completas

1. **Beutel, J., List, S., & von Schweinitz, G. (2019).** "Does machine learning help us predict banking crises?" *Deutsche Bundesbank Discussion Paper*.

2. **Adrian, T., Grinberg, F., Liang, N., & Malik, S. (2019).** "The Term Structure of Growth-at-Risk." *IMF Working Paper*.

3. **Lo Duca, M., et al. (2017).** "A new database for financial crises in European countries." *ECB Occasional Paper*.

4. **Aldasoro, I., Borio, C., & Drehmann, M. (2018).** "Early warning indicators of banking crises: expanding the family." *BIS Quarterly Review*.

5. **Alessi, L., & Detken, C. (2018).** "Identifying excessive credit growth and leverage." *Journal of Financial Stability*.

6. **Chen, T., & Guestrin, C. (2016).** "XGBoost: A Scalable Tree Boosting System." *KDD 2016*.

7. **Heaton, J. B., Polson, N. G., & Witte, J. H. (2017).** "Deep learning for finance: deep portfolios." *Applied Stochastic Models in Business and Industry*.

8. **Ozbayoglu, A. M., Gudelek, M. U., & Sezer, O. B. (2020).** "Deep learning for financial applications: A survey." *Applied Soft Computing*.
